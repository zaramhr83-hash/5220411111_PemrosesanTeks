{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60ad2925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Sastrawi in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.0.1)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\ACER\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pip install Sastrawi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2fdc018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Sastrawi in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.0.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\ACER\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting gensim\n",
      "  Using cached gensim-4.4.0-cp310-cp310-win_amd64.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gensim) (1.24.1)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gensim) (1.15.3)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gensim) (7.5.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\acer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
      "Downloading gensim-4.4.0-cp310-cp310-win_amd64.whl (24.4 MB)\n",
      "   ---------------------------------------- 0.0/24.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.6/24.4 MB 10.5 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 3.4/24.4 MB 9.6 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 5.5/24.4 MB 10.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 7.9/24.4 MB 10.1 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 10.5/24.4 MB 10.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 13.1/24.4 MB 11.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 15.2/24.4 MB 11.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 17.8/24.4 MB 11.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 19.7/24.4 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 21.0/24.4 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.8/24.4 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.4/24.4 MB 9.6 MB/s  0:00:02\n",
      "Installing collected packages: gensim\n",
      "Successfully installed gensim-4.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install Sastrawi gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f9a712",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ACER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\ACER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# IMPORT LIBRARY\n",
    "# ============================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from gensim.models import Word2Vec \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "# Preprocessing\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "# Feature extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# Models\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# ============================================================\n",
    "# KONFIGURASI DATASET\n",
    "# ============================================================\n",
    "RANDOM_STATE = 42\n",
    "CSV_PATH = \"dataset_manual_label.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "492f3e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah data: 250\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned_full</th>\n",
       "      <th>manual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kepo bgt adekkkk??????????????</td>\n",
       "      <td>kepo adekkkk</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buah jatuh se pohon \" nya????</td>\n",
       "      <td>buah jatuh se pohon nya</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cushion Nya kegelapan ga sihhh??</td>\n",
       "      <td>cushion nya kegelapan sihhh</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LU APAIN PONI BOCIL ITU KAK JENNN?!!! KENAPA L...</td>\n",
       "      <td>lu apain poni bocil kak jennn kenapa lu buat s...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mayi gamau kalah cantik sama mamanya????</td>\n",
       "      <td>mayi gamau kalah cantik sama mamanya</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                     kepo bgt adekkkk??????????????   \n",
       "1                      buah jatuh se pohon \" nya????   \n",
       "2                   Cushion Nya kegelapan ga sihhh??   \n",
       "3  LU APAIN PONI BOCIL ITU KAK JENNN?!!! KENAPA L...   \n",
       "4           mayi gamau kalah cantik sama mamanya????   \n",
       "\n",
       "                                   text_cleaned_full   manual  \n",
       "0                                       kepo adekkkk  negatif  \n",
       "1                            buah jatuh se pohon nya  negatif  \n",
       "2                        cushion nya kegelapan sihhh  negatif  \n",
       "3  lu apain poni bocil kak jennn kenapa lu buat s...  negatif  \n",
       "4               mayi gamau kalah cantik sama mamanya  negatif  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(CSV_PATH, encoding='latin-1', sep=';')\n",
    "\n",
    "print(\"Jumlah data:\", len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63972fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup stopwords, stemmer, dan fungsi preprocess (stemm + simple lemmatize)\n",
    "\n",
    "# Stopwords & stemmer Sastrawi\n",
    "stopword_factory = StopWordRemoverFactory()\n",
    "STOP_WORDS = set(stopword_factory.get_stop_words())\n",
    "\n",
    "stemmer = StemmerFactory().create_stemmer()\n",
    "\n",
    "# Simple lemmatization dictionary (tambahkan sesuai kebutuhan dataset)\n",
    "LEMMATIZE_DICT = {\n",
    "    \"kegabutan\": \"gabut\",\n",
    "    \"kegelapan\": \"gelap\",\n",
    "    \"gamau\": \"tidak mau\",\n",
    "    \"kepo\": \"ingin tahu\",\n",
    "    \"poni\": \"poni\", \n",
    "    \"kak\": \"kakak\",\n",
    "    \"adekkkk\": \"adik\",\n",
    "}\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Steps:\n",
    "    - safe check NA\n",
    "    - lowercase, remove non-letters (retain spaces)\n",
    "    - tokenize by whitespace\n",
    "    - remove stopwords\n",
    "    - sastrawi stem per token\n",
    "    - simple lemmatize by dict\n",
    "    - join back\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    s = str(text).lower()\n",
    "    s = re.sub(r'[^a-z\\s]', ' ', s)  # hanya huruf a-z (indonesia), angka/punctuation -> space\n",
    "    toks = s.split()\n",
    "    toks = [t for t in toks if t and t not in STOP_WORDS]\n",
    "    # stem each token\n",
    "    stemmed = [stemmer.stem(t) for t in toks]\n",
    "    # lemmatize via dictionary fallback\n",
    "    lemm = [LEMMATIZE_DICT.get(t, t) for t in stemmed]\n",
    "    return \" \".join(lemm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf2822f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PREVIEW DATASET ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned_full</th>\n",
       "      <th>manual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kepo bgt adekkkk??????????????</td>\n",
       "      <td>kepo adekkkk</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buah jatuh se pohon \" nya????</td>\n",
       "      <td>buah jatuh se pohon nya</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cushion Nya kegelapan ga sihhh??</td>\n",
       "      <td>cushion nya kegelapan sihhh</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LU APAIN PONI BOCIL ITU KAK JENNN?!!! KENAPA L...</td>\n",
       "      <td>lu apain poni bocil kak jennn kenapa lu buat s...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mayi gamau kalah cantik sama mamanya????</td>\n",
       "      <td>mayi gamau kalah cantik sama mamanya</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                     kepo bgt adekkkk??????????????   \n",
       "1                      buah jatuh se pohon \" nya????   \n",
       "2                   Cushion Nya kegelapan ga sihhh??   \n",
       "3  LU APAIN PONI BOCIL ITU KAK JENNN?!!! KENAPA L...   \n",
       "4           mayi gamau kalah cantik sama mamanya????   \n",
       "\n",
       "                                   text_cleaned_full   manual  \n",
       "0                                       kepo adekkkk  negatif  \n",
       "1                            buah jatuh se pohon nya  negatif  \n",
       "2                        cushion nya kegelapan sihhh  negatif  \n",
       "3  lu apain poni bocil kak jennn kenapa lu buat s...  negatif  \n",
       "4               mayi gamau kalah cantik sama mamanya  negatif  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DISTRIBUSI LABEL ===\n",
      "manual\n",
      "negatif    100\n",
      "positif    100\n",
      "netral      50\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- LOAD DATA ---\n",
    "if not os.path.exists(CSV_PATH):\n",
    "    raise FileNotFoundError(f\"File tidak ditemukan: {CSV_PATH}\")\n",
    "\n",
    "df = pd.read_csv(CSV_PATH, encoding='latin-1', sep=';')\n",
    "\n",
    "print(\"=== PREVIEW DATASET ===\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\n=== DISTRIBUSI LABEL ===\")\n",
    "print(df[\"manual\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1d5617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Menggunakan kolom teks: text_cleaned_full\n",
      "\n",
      "[INFO] Melakukan preprocessing (stem + lemmatization)...\n",
      "\n",
      "=== DISTRIBUSI LABEL SETELAH SPLIT ===\n",
      "Train: {'negatif': 80, 'netral': 40, 'positif': 80}\n",
      "Test : {'positif': 20, 'negatif': 20, 'netral': 10}\n"
     ]
    }
   ],
   "source": [
    "possible_cols = [\"text_cleaned_full\", \"clean_text\", \"manual\", \"text\"]\n",
    "\n",
    "text_col = None\n",
    "for col in possible_cols:\n",
    "    if col in df.columns:\n",
    "        text_col = col\n",
    "        break\n",
    "\n",
    "if text_col is None:\n",
    "    raise ValueError(f\"Tidak ada kolom teks. Minimal salah satu kolom harus ada: {possible_cols}\")\n",
    "\n",
    "print(f\"\\nMenggunakan kolom teks: {text_col}\")\n",
    "\n",
    "# --- PERSIAPAN TEKS & LABEL ---\n",
    "df = df.dropna(subset=[\"manual\"]).reset_index(drop=True)\n",
    "texts_raw  = df[text_col].astype(str)\n",
    "labels_raw = df[\"manual\"].astype(str)\n",
    "\n",
    "\n",
    "print(\"\\n[INFO] Melakukan preprocessing (stem + lemmatization)...\")\n",
    "texts_processed = texts_raw.apply(preprocess_text)\n",
    "\n",
    "# --- TRAIN-TEST SPLIT ---\n",
    "try:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        texts_processed,\n",
    "        labels_raw,\n",
    "        test_size=0.2,\n",
    "        random_state=RANDOM_STATE,\n",
    "        stratify=labels_raw\n",
    "    )\n",
    "except ValueError:\n",
    "    print(\"[WARNING] Stratify gagal (kelas terlalu sedikit). Melakukan split tanpa stratify.\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        texts_processed,\n",
    "        labels_raw,\n",
    "        test_size=0.2,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "print(\"\\n=== DISTRIBUSI LABEL SETELAH SPLIT ===\")\n",
    "print(\"Train:\", dict(Counter(y_train)))\n",
    "print(\"Test :\", dict(Counter(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "265f6b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Percobaan 1: TF-IDF + LinearSVC ===\n",
      "Akurasi: 0.5000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.50      0.40      0.44        20\n",
      "      netral       0.11      0.10      0.11        10\n",
      "     positif       0.64      0.80      0.71        20\n",
      "\n",
      "    accuracy                           0.50        50\n",
      "   macro avg       0.42      0.43      0.42        50\n",
      "weighted avg       0.48      0.50      0.48        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF + LinearSVC\n",
    "print(\"=== Percobaan 1: TF-IDF + LinearSVC ===\")\n",
    "pipe1 = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(max_features=15000, ngram_range=(1,2), sublinear_tf=True, min_df=2)),\n",
    "    (\"svc\", LinearSVC(class_weight=\"balanced\", random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "pipe1.fit(X_train, y_train)\n",
    "pred1 = pipe1.predict(X_test)\n",
    "\n",
    "acc1 = accuracy_score(y_test, pred1)\n",
    "print(f\"Akurasi: {acc1:.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, pred1, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e68f74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Percobaan 2: BOW (CountVectorizer) + MultinomialNB ===\n",
      "Akurasi: 0.5400\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.54      0.70      0.61        20\n",
      "      netral       0.33      0.10      0.15        10\n",
      "     positif       0.57      0.60      0.59        20\n",
      "\n",
      "    accuracy                           0.54        50\n",
      "   macro avg       0.48      0.47      0.45        50\n",
      "weighted avg       0.51      0.54      0.51        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BOW + MultinomialNB\n",
    "print(\"=== Percobaan 2: BOW (CountVectorizer) + MultinomialNB ===\")\n",
    "pipe2 = Pipeline([\n",
    "    (\"bow\", CountVectorizer(max_features=15000, ngram_range=(1,2), min_df=2)),\n",
    "    (\"nb\", MultinomialNB())\n",
    "])\n",
    "\n",
    "pipe2.fit(X_train, y_train)\n",
    "pred2 = pipe2.predict(X_test)\n",
    "\n",
    "acc2 = accuracy_score(y_test, pred2)\n",
    "print(f\"Akurasi: {acc2:.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, pred2, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c7699bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Percobaan 3: Word2Vec(avg) + LogisticRegression ===\n",
      "Akurasi: 0.4600\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.50      0.55      0.52        20\n",
      "      netral       0.00      0.00      0.00        10\n",
      "     positif       0.55      0.60      0.57        20\n",
      "\n",
      "    accuracy                           0.46        50\n",
      "   macro avg       0.35      0.38      0.37        50\n",
      "weighted avg       0.42      0.46      0.44        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Word2Vec + average embeddings + LogisticRegression\n",
    "print(\"=== Percobaan 3: Word2Vec(avg) + LogisticRegression ===\")\n",
    "\n",
    "def tokenize_list(texts):\n",
    "    return [t.split() for t in texts]\n",
    "\n",
    "sentences = tokenize_list(X_train.tolist())\n",
    "w2v_size = 100\n",
    "w2v = Word2Vec(sentences, vector_size=w2v_size, window=5, min_count=1, workers=4, seed=RANDOM_STATE, epochs=20)\n",
    "\n",
    "def avg_vector(text, model, size=w2v_size):\n",
    "    toks = text.split()\n",
    "    vecs = [model.wv[t] for t in toks if t in model.wv]\n",
    "    if len(vecs) == 0:\n",
    "        return np.zeros(size)\n",
    "    return np.mean(vecs, axis=0)\n",
    "\n",
    "X_train_vec = np.vstack([avg_vector(t, w2v) for t in X_train])\n",
    "X_test_vec  = np.vstack([avg_vector(t, w2v) for t in X_test])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train_vec)\n",
    "X_test_s  = scaler.transform(X_test_vec)\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000, class_weight=\"balanced\", random_state=RANDOM_STATE)\n",
    "lr.fit(X_train_s, y_train)\n",
    "pred3 = lr.predict(X_test_s)\n",
    "\n",
    "acc3 = accuracy_score(y_test, pred3)\n",
    "print(f\"Akurasi: {acc3:.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, pred3, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "99f1489f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Percobaan 4: TF-IDF + RandomForest ===\n",
      "Akurasi: 0.4800\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.67      0.50      0.57        20\n",
      "      netral       0.11      0.20      0.14        10\n",
      "     positif       0.71      0.60      0.65        20\n",
      "\n",
      "    accuracy                           0.48        50\n",
      "   macro avg       0.49      0.43      0.45        50\n",
      "weighted avg       0.57      0.48      0.52        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF + RandomForest\n",
    "print(\"=== Percobaan 4: TF-IDF + RandomForest ===\")\n",
    "pipe4 = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(max_features=10000, ngram_range=(1,2), min_df=2)),\n",
    "    (\"rf\", RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE, n_jobs=-1, class_weight=\"balanced_subsample\"))\n",
    "])\n",
    "\n",
    "pipe4.fit(X_train, y_train)\n",
    "pred4 = pipe4.predict(X_test)\n",
    "\n",
    "acc4 = accuracy_score(y_test, pred4)\n",
    "print(f\"Akurasi: {acc4:.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, pred4, zero_division=0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
